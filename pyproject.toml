[tool.poetry]
name = "chatllm"
version = "0.1.0"
description = "Interact with Local LLMs and LLM Apis using Gradio and CLI"
authors = ["Christy George <christy.george@gmail.com>"]
license = "Unlicense"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"
gradio = "^3.45.2"
llama-cpp-python = "^0.2.9"
openai = "^0.28.1"
python-dotenv = "^1.0.0"
tiktoken = "^0.5.1"
torch = "^2.0.1"
transformers = "^4.33.3"
accelerate = "^0.23.0"
bitsandbytes = "^0.41.1"
replicate = "^0.14.0"
einops = "^0.7.0"
pytest-asyncio = "^0.21.1"
click-repl = "^0.3.0"
colorama = "^0.4.6"
click = "^8.1.7"
google-cloud-aiplatform = "^1.36.0"
google-generativeai = "^0.2.2"


[tool.poetry.group.dev.dependencies]
pytest = "^7.4.2"
bandit = "^1.7.5"
mypy = "^1.5.1"
black = "^23.9.1"
types-requests = "^2.31.0.8"
pre-commit = "^3.4.0"
isort = "^5.12.0"
flake8-pyproject = "^1.2.3"

[tool.pytest.ini_options]
pythonpath = [
  "chatllm"
]
log_cli_level = "WARNING" # override with --log-cli-level=INFO
log_cli_format = "%(asctime)s %(levelname)s [%(name)s]: %(message)s"
log_cli_date_format = "%H:%M:%S"
log_level = "INFO"
log_format = "%(asctime)s %(levelname)s [%(name)s]: %(message)s"
log_date_format = "%H:%M:%S"

[tool.flake8]
# Ignore E501 (Line length) because black takes care of it
ignore = ['W503', 'E231', 'E241', 'E501']
per-file-ignores = [
    '__init__.py:F401',
]
max-line-length = 100 # So that it doesn't clash with black
count = true
show-source = true

[tool.mypy]
show_error_codes = true
show_error_context = true
show_column_numbers = true
# plugins = "pydantic.mypy"

[tool.black]
line-length = 100

[tool.bandit]
exclude_dirs = ["tests", "./.history", "./.venv", "./.git"]

[tool.isort]
profile = "black"
lines_between_types = 0

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
